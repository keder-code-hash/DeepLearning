{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,AveragePooling2D,Dense,Flatten\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as plt \n",
    "from matplotlib.pyplot import imread,imshow,get_cmap\n",
    "train_dir=\"data/traindata/\"\n",
    "dir_list=os.listdir(train_dir)\n",
    "\n",
    "img=imread(os.path.join(train_dir,(str(dir_list[0]))))\n",
    "imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to classify the data manually.Means dogs and cats are kept in two sepertae\n",
    "# folder.So that we can tell which belongs to which class.\n",
    "\n",
    "import os,shutil\n",
    "directory_path='data/traindata/'\n",
    "sub_dir=os.listdir(directory_path)\n",
    "# print(sub_dir)\n",
    "file_path=os.path.join(directory_path,str(sub_dir[0]))\n",
    "\n",
    "all_files=os.listdir(file_path)\n",
    "\n",
    "cat_class=os.path.join(file_path,'cat')\n",
    "dog_class=os.path.join(file_path,'dog')\n",
    "\n",
    "# cat_dir=os.mkdir(cat_class)\n",
    "# dog_dir=os.mkdir(dog_class)\n",
    "\n",
    "for file in all_files:\n",
    "    original=os.path.join(file_path,str(file))\n",
    "    if str(file).split('.').count('cat')>0:\n",
    "        target=os.path.join(file_path,'cat')\n",
    "        shutil.move(original,target)\n",
    "        print(str(file))\n",
    "        #move to cat class \n",
    "    if str(file).split('.').count('dog')>0:\n",
    "        target=os.path.join(file_path,'dog')\n",
    "        shutil.move(original,target)\n",
    "        print(str(file))\n",
    "        #move to dog \n",
    "# print(all_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 12500 images belonging to 1 classes.\n",
      "<keras.preprocessing.image.DirectoryIterator object at 0x000001C28CCFB850> <keras.preprocessing.image.DirectoryIterator object at 0x000001C2D40F2280> <keras.preprocessing.image.DirectoryIterator object at 0x000001C2D40FCE80>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_directory/\n",
    "train_data_gen=ImageDataGenerator(\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.5,\n",
    "        height_shift_range=0.5,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.20)\n",
    "\n",
    "test_data_gen=ImageDataGenerator(\n",
    "        rescale=1./255\n",
    ")\n",
    "# categorical means return a 2d hot encoded image\n",
    "\n",
    "# one_hot_encoding : One-Hot Encoding is another popular technique for treating categorical variables. It simply creates additional features based on the number of unique values in the categorical feature. Every unique value in the category will be added as a feature.\n",
    "\n",
    "# https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
    "\n",
    "batch_size=8\n",
    "# small batch size leads to bigger BatchDataset\n",
    "# shuffle: Whether to shuffle the data. Default: True. If set to False, sorts the data in alphanumeric order.\n",
    "# seed: Optional random seed for shuffling and transformations.\n",
    "seed=42\n",
    "tr_data_dir_iterator=train_data_gen.flow_from_directory(\n",
    "        directory=\"data/traindata/train/\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        target_size=(224,224),\n",
    "        seed=seed, \n",
    "        shuffle=True,\n",
    "        subset='training')\n",
    "valid_data_dir_iterator=train_data_gen.flow_from_directory(\n",
    "        directory=\"data/traindata/train/\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        target_size=(224,224),\n",
    "        seed=seed, \n",
    "        shuffle=True,\n",
    "        subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "test_data_dir_iterator=test_data_gen.flow_from_directory(\n",
    "        directory=\"data/testdata/\",\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        color_mode=\"rgb\",\n",
    "        target_size=(224,224),\n",
    "        shuffle=False,\n",
    "        seed=seed\n",
    ")\n",
    "print(tr_data_dir_iterator,valid_data_dir_iterator,test_data_dir_iterator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_26 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 112, 112, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 56, 56, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 28, 28, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 14, 14, 512)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 7, 7, 512)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1000)              4097000   \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 2)                 2002      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,359,546\n",
      "Trainable params: 138,359,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# vgg-16 network\n",
    "\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=1000,activation=\"relu\"))\n",
    "## as out puts can be of two types\n",
    "model.add(Dense(units=2,activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "# ModelCheckpoint helps us to save the model by monitoring a specific parameter of the model. In this case we are monitoring validation accuracy by passing val_acc to ModelCheckpoint. The model will only be saved to disk if the validation accuracy of the model in current epoch is greater than what it was in the last epoch.\n",
    "\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "# here patience is set to 20 means if accuracy is not increamenting after 20 epochs, exit from training.\n",
    "\n",
    "hist = model.fit_generator(steps_per_epoch=tr_data_dir_iterator.n//tr_data_dir_iterator.batch_size,generator=tr_data_dir_iterator, validation_data= valid_data_dir_iterator, validation_steps=valid_data_dir_iterator.n//valid_data_dir_iterator.batch_size,epochs=40,callbacks=[checkpoint,early])\n",
    "# The validation generator works exactly like the training generator. You define how many batches it will wield per epoch.\n",
    "\n",
    "# The training generator will yield steps_per_epoch batches.\n",
    "# When the epoch ends, the validation generator will yield validation_steps batches.\n",
    "# steps_per_epoch = TotalTrainingSamples / TrainingBatchSize\n",
    "# validation_steps = TotalvalidationSamples / ValidationBatchSize\n",
    "# https://stackoverflow.com/questions/45943675/meaning-of-validation-steps-in-keras-sequential-fit-generator-parameter-list"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7cd222c8c58511d6534408547d0f6dab3521bfce46c6656cd95ea4e50abe6c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
