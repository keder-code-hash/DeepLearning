{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Dropout,BatchNormalization,Dense,Flatten\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 25000 files belonging to 2 classes.\n",
      "Using 20000 files for training.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "Using 5000 files for validation.\n"
     ]
    }
   ],
   "source": [
    "image_size=(224,224)\n",
    "batch_size=64\n",
    "seed=1337\n",
    "\n",
    "train_data_set=tensorflow.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"data/traindata/train/\",\n",
    "    validation_split=0.20,\n",
    "    subset=\"training\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    interpolation='bilinear'\n",
    ")\n",
    "validation_data_set=tensorflow.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=\"data/traindata/train/\",\n",
    "    validation_split=0.20,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    interpolation='bilinear'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for images,labels in train_data_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation in image for generating more data\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "for images,_ in train_data_set.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KEDERN~1\\AppData\\Local\\Temp/ipykernel_2664/4222499053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRescaling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KEDERN~1\\AppData\\Local\\Temp/ipykernel_2664/4222499053.py\u001b[0m in \u001b[0;36mmake_model\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_augmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRescaling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\engine\\input_layer.py\u001b[0m in \u001b[0;36mInput\u001b[1;34m(shape, batch_size, name, dtype, sparse, tensor, ragged, type_spec, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m   if (batch_input_shape is None and shape is None and tensor is None\n\u001b[0;32m    372\u001b[0m       and type_spec is None):\n\u001b[1;32m--> 373\u001b[1;33m     raise ValueError('Please provide to Input a `shape`'\n\u001b[0m\u001b[0;32m    374\u001b[0m                      \u001b[1;34m' or a `tensor` or a `type_spec` argument. Note that '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m                      \u001b[1;34m'`shape` does not include the batch '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Please provide to Input a `shape` or a `tensor` or a `type_spec` argument. Note that `shape` does not include the batch dimension."
     ]
    }
   ],
   "source": [
    "def make_model():\n",
    "    inputs=keras.Input(input_shape=(224,224))\n",
    "    x = data_augmentation(inputs)\n",
    "    x = layers.Rescaling(1./255)(x)\n",
    "\n",
    "    # vgg-16 network\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=128,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=128,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=256,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "    model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(Conv2D(filters=512,kernel_size=(3,3),padding=\"same\",activation=\"relu\"))\n",
    "    model.add(MaxPooling2D(strides=(2,2),pool_size=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dense(units=4096,activation=\"relu\"))\n",
    "    model.add(Dense(units=1000,activation=\"relu\"))\n",
    "    ## as out puts can be of two types\n",
    "    model.add(Dense(units=2,activation=\"softmax\"))\n",
    "    model.summary()\n",
    "\n",
    "    \n",
    "    print(x)\n",
    "make_model()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have to classify the data manually.Means dogs and cats are kept in two sepertae\n",
    "# folder.So that we can tell which belongs to which class.\n",
    "\n",
    "import os,shutil\n",
    "directory_path='data/traindata/'\n",
    "sub_dir=os.listdir(directory_path)\n",
    "# print(sub_dir)\n",
    "file_path=os.path.join(directory_path,str(sub_dir[0]))\n",
    "\n",
    "all_files=os.listdir(file_path)\n",
    "\n",
    "cat_class=os.path.join(file_path,'cat')\n",
    "dog_class=os.path.join(file_path,'dog')\n",
    "\n",
    "cat_dir=os.mkdir(cat_class)\n",
    "dog_dir=os.mkdir(dog_class)\n",
    "\n",
    "for file in all_files:\n",
    "    original=os.path.join(file_path,str(file))\n",
    "    if str(file).split('.').count('cat')>0:\n",
    "        target=os.path.join(file_path,'cat')\n",
    "        shutil.move(original,target)\n",
    "        print(str(file))\n",
    "        #move to cat class \n",
    "    if str(file).split('.').count('dog')>0:\n",
    "        target=os.path.join(file_path,'dog')\n",
    "        shutil.move(original,target)\n",
    "        print(str(file))\n",
    "        #move to dog \n",
    "# print(all_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# https://studymachinelearning.com/keras-imagedatagenerator-with-flow_from_directory/\n",
    "train_data_gen=ImageDataGenerator(\n",
    "        rotation_range=0,\n",
    "        width_shift_range=0.5,\n",
    "        height_shift_range=0.5,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        validation_split=0.20)\n",
    "\n",
    "test_data_gen=ImageDataGenerator(\n",
    "        rescale=1./255\n",
    ")\n",
    "# categorical means return a 2d hot encoded image\n",
    "\n",
    "# one_hot_encoding : One-Hot Encoding is another popular technique for treating categorical variables. It simply creates additional features based on the number of unique values in the categorical feature. Every unique value in the category will be added as a feature.\n",
    "\n",
    "# https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
    "\n",
    "batch_size=64\n",
    "# small batch size leads to bigger BatchDataset\n",
    "# shuffle: Whether to shuffle the data. Default: True. If set to False, sorts the data in alphanumeric order.\n",
    "# seed: Optional random seed for shuffling and transformations.\n",
    "seed=42\n",
    "tr_data_dir_iterator=train_data_gen.flow_from_directory(\n",
    "        directory=\"data/traindata/train/\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        target_size=(224,224),\n",
    "        seed=seed, \n",
    "        shuffle=True,\n",
    "        subset='training')\n",
    "valid_data_dir_iterator=train_data_gen.flow_from_directory(\n",
    "        directory=\"data/traindata/train/\",\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        target_size=(224,224), \n",
    "        seed=seed, \n",
    "        shuffle=True,\n",
    "        subset='validation'\n",
    ")\n",
    "\n",
    "\n",
    "test_data_dir_iterator=test_data_gen.flow_from_directory(\n",
    "        directory=\"data/testdata/\",\n",
    "        batch_size=1,\n",
    "        class_mode=None,\n",
    "        color_mode=\"rgb\",\n",
    "        target_size=(224,224),\n",
    "        shuffle=False,\n",
    "        seed=seed\n",
    ")\n",
    "print(tr_data_dir_iterator,valid_data_dir_iterator,test_data_dir_iterator)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib as plt \n",
    "from matplotlib.pyplot import imread,imshow,get_cmap\n",
    "train_dir=\"data/traindata/train/dog/\"\n",
    "dir_list=os.listdir(train_dir)\n",
    "\n",
    "img=imread(os.path.join(train_dir,(str(dir_list[0]))))\n",
    "imshow(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7cd222c8c58511d6534408547d0f6dab3521bfce46c6656cd95ea4e50abe6c2"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
